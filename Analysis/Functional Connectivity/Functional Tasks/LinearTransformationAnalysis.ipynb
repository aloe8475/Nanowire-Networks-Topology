{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Comparison of ASN with WS and C. Elegans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates 24 different ASN networks with 300 nodes, each of which has differing parameters (Average Path length, Wire Dispersion and Centroid Dispersion). \n",
    "\n",
    "We then find the average degree for each ASN network, and use that as 2k to generate corresponding grid-like, small-world and random Watts-Strogatz networks.\n",
    "\n",
    "We also load a sample C. Elegans network for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter notebook --version\n",
    "# !python --version\n",
    "# !conda --version\n",
    "# # !jupyter trust RunTasksDifferentNetworks_MultipleNetworks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/suphys/aloe8475\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/import/silo2/aloe8475/Documents/edamame\n"
     ]
    }
   ],
   "source": [
    "cd \"Documents/edamame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import datetime\n",
    "import networkx as nx\n",
    "from edamame import *\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import edamame.core.wires as wires\n",
    "from random import choice\n",
    "import warnings\n",
    "from IPython.core.debugger import set_trace\n",
    "import nct\n",
    "import bct\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "def compressed_pickle(obj, filename,protocol=-1):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        cPickle.dump(obj, f, protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_pickle(file):\n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        loaded_object = cPickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_seed2=700\n",
    "def connected_component_subgraphs(G):\n",
    "    for c in nx.connected_components(G):\n",
    "        yield G.subgraph(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Largest Components\n",
    "def select_largest_component_new(wires_dict):\n",
    "    \"\"\"\n",
    "    Find and select largest connected component of the original graph G.\n",
    "    Throws away unconnected components and updates all the keys in wires_dict \n",
    "    \"\"\"\n",
    "#     def connected_component_subgraphs(G):\n",
    "#         for c in nx.connected_components(G):\n",
    "#             yield G.subgraph(c)\n",
    "    \n",
    "    wires_dict['G'] = max(connected_component_subgraphs(wires_dict['G']), key=len)\n",
    "#     set_trace()\n",
    "    nw = len(wires_dict['G'].nodes())\n",
    "    nj = len(wires_dict['G'].edges())   \n",
    "    \n",
    "    logging.info(\"The largest component has %5d nodes and %6d edges\", nw, nj)\n",
    "\n",
    "    # Replace values in the dictionary\n",
    "    wires_dict['number_of_wires']     = nw\n",
    "    wires_dict['number_of_junctions'] = nj\n",
    "    wires_dict['xa'] = wires_dict['xa'][wires_dict['G'].nodes()] \n",
    "    wires_dict['ya'] = wires_dict['ya'][wires_dict['G'].nodes()] \n",
    "    wires_dict['xb'] = wires_dict['xb'][wires_dict['G'].nodes()] \n",
    "    wires_dict['yb'] = wires_dict['yb'][wires_dict['G'].nodes()]\n",
    "    wires_dict['xc'] = wires_dict['xc'][wires_dict['G'].nodes()] \n",
    "    wires_dict['yc'] = wires_dict['yc'][wires_dict['G'].nodes()]\n",
    " \n",
    "    # Keep old edge_list\n",
    "    old_edge_list = [(ii, kk) for ii, kk in  zip(wires_dict['edge_list'][:, 0], wires_dict['edge_list'][:, 1])]\n",
    "    # Remove old edge list\n",
    "    wires_dict = wires.remove_key(wires_dict, 'edge_list') \n",
    "    # Save indices of intersections in the old graph\n",
    "    ind_dict = {key:value for value,key in enumerate(old_edge_list)}\n",
    "    new_edge_list = sorted([kk if kk[0] < kk[1] else (kk[1], kk[0]) for kk in wires_dict['G'].edges()], key=lambda x: x[0])\n",
    "    # Find intersection between the two sets\n",
    "    inter = set(ind_dict).intersection(new_edge_list)\n",
    "    # Retrieve edge indices/positions from the old list\n",
    "    edges_idx = [ind_dict[idx] for idx in inter]\n",
    "       \n",
    "    # These have length equal to number of junctions -- only get the ones we need\n",
    "    wires_dict['xi'] = wires_dict['xi'][edges_idx] \n",
    "    wires_dict['yi'] = wires_dict['yi'][edges_idx] \n",
    "    \n",
    "    # Get contiguous numbering of nodes\n",
    "    # Build node mapping \n",
    "    node_mapping    = {key:value for value, key in enumerate(sorted(wires_dict['G'].nodes()))}\n",
    "    # This  step also renames edges list\n",
    "    wires_dict['G'] =  nx.relabel_nodes(wires_dict['G'] , node_mapping)\n",
    "\n",
    "    # Swap node vertices if vertex 0 is larger than vertex 1, then sort by first element\n",
    "    wires_dict['edge_list'] = np.asarray(sorted([kk if kk[0] < kk[1] else (kk[1], kk[0]) for kk in wires_dict['G'].edges()], key=lambda x: x[0]))\n",
    "    \n",
    "    # Save adjacency matrix of new graph\n",
    "    wires_dict = wires.remove_key(wires_dict, 'adj_matrix') \n",
    "    wires_dict = wires.generate_adj_matrix(wires_dict)\n",
    "\n",
    "    wire_distances = wires.cdist(np.array([wires_dict['xc'], wires_dict['yc']]).T, np.array([wires_dict['xc'], wires_dict['yc']]).T, metric='euclidean')    \n",
    "    wires_dict['wire_distances'] = wire_distances\n",
    "\n",
    "    return wires_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Structural Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/import/silo2/aloe8475/Documents/CODE/Analysis/Functional Connectivity/Functional Tasks\n"
     ]
    }
   ],
   "source": [
    "cd \"/import/silo2/aloe8475/Documents/CODE/Analysis/Functional Connectivity/Functional Tasks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elegans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Elegans Networks\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "name='elegans_LinearTransformation.pkl'\n",
    "print('Loading Elegans Networks')\n",
    "file = open(name, 'rb')\n",
    "#     [ASN300,cluster1,cluster2,cluster3,time_index,nodesList] = pickle.load(file)\n",
    "#     [ASN300,cluster1,cluster2,cluster3] = pickle.load(file)\n",
    "[Elegans] = pickle.load(file)\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "elegansGraph=Elegans['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small world calculated on C Elegans Matrix in smallworld.m in MATLAB\n",
    "temp=loadmat(r'cElegans_smallworld.mat')\n",
    "smallworld_elegans=temp['cElegansSW'][0]\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Worldness: \n",
    "# ------------------------------------\n",
    "# CALCULATED IN MATLAB: smallworldness.m \n",
    "# found in C:\\Users\\aloe8475\\Documents\\PhD\\GitHub\\CODE\\Analysis\\Functional Connectivity\\Functional Tasks\n",
    "# ------------------------------------\n",
    "temp=loadmat(r'300nwASN_multipleNetworks_smallworld.mat')\n",
    "smallworld=temp['smallworld']\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Networks + Linear Transformation Results\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "name='networks_LinearTransformation.pkl'\n",
    "print('Loading Networks + Linear Transformation Results')\n",
    "file = open(name, 'rb')\n",
    "#     [ASN300,cluster1,cluster2,cluster3,time_index,nodesList] = pickle.load(file)\n",
    "#     [ASN300,cluster1,cluster2,cluster3] = pickle.load(file)\n",
    "[ASN300] = pickle.load(file)\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Linear  Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression\n",
    "def NOKEVregression(target,absV): \n",
    "    inputx=np.vstack((np.ones(len(target)),absV)).T\n",
    "    a1=np.linalg.lstsq(inputx,target)\n",
    "    return a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subgraph AdjMat\n",
    "\n",
    "#Threshold by conductance - when tunnelling becomes appreciable (offResistance * 10)\n",
    "\n",
    "def getOnGraph(network, this_TimeStamp = 0):\n",
    "    edgeList = network.connectivity.edge_list\n",
    "    adjMat = np.zeros((network.numOfWires, network.numOfWires))\n",
    "#     set_trace()\n",
    "    adjMat[edgeList[:,0], edgeList[:,1]] = (1/network.junctionResistance[this_TimeStamp,:])>1e-06#network.junctionSwitch[this_TimeStamp,:] #CHANGE THIS TO CONDUCTANCE THRESHOLD?\n",
    "    adjMat[edgeList[:,1], edgeList[:,0]] = (1/network.junctionResistance[this_TimeStamp,:])>1e-06#network.junctionSwitch[this_TimeStamp,:] #CHANGE THIS TO CONDUCTANCE THRESHOLD?\n",
    "    onGraph = nx.from_numpy_array(adjMat)\n",
    "    onGraph=nx.DiGraph.to_undirected(onGraph)\n",
    "    \n",
    "    return onGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubGraphComm(network, this_TimeStamp = 0):\n",
    "    onGraph = getOnGraph(network, this_TimeStamp)\n",
    "    components = [i for i in nx.connected_components(onGraph)]\n",
    "    giant_component = components[np.argmax([len(i) for i in nx.connected_components(onGraph)])]\n",
    "    nodes = list(giant_component)\n",
    "    commMat = np.zeros((network.numOfWires, network.numOfWires))\n",
    "    subComm = nx.communicability(onGraph.subgraph(giant_component))\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            commMat[i,j] = subComm[i][j]\n",
    "    return commMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Communicability + Current Matrices\n",
    "def commCurr(sim):\n",
    "    startTime=500\n",
    "    timeSteps=50\n",
    "    endTime=1500\n",
    "    time_index=[startTime,endTime,timeSteps]#]len(sim.junctionResistance),timeSteps]\n",
    "    currMat=[None]*len(range(startTime,endTime,timeSteps))#startTime,len(sim.junctionResistance),timeSteps))\n",
    "    nodesListFull=[None]*len(range(startTime,endTime,timeSteps))#startTime,len(sim.junctionResistance),timeSteps))\n",
    "    commu_Mat=[None]*len(range(startTime,endTime,timeSteps))#startTime,len(sim.junctionResistance),timeSteps))\n",
    "    new_currGraph=[None]*len(range(startTime,endTime,timeSteps))#startTime,len(sim.junctionResistance),timeSteps))\n",
    "    count = 0\n",
    "    for i in tqdm(range(startTime,endTime,timeSteps)):#startTime,len(sim.junctionResistance),timeSteps)): #for each timestep\n",
    "        currMat[count] = np.zeros((sim.numOfWires,sim.numOfWires))\n",
    "        edgeList = sim.connectivity.edge_list\n",
    "        currMat[count][edgeList[:,0], edgeList[:,1]] = sim.junctionVoltage[i,:]/sim.junctionResistance[i,:] #-1,:\n",
    "        currMat[count] = currMat[count] + currMat[count].T\n",
    "        currGraph = nx.from_numpy_array(currMat[count])\n",
    "        subGraph = getOnGraph(sim, this_TimeStamp=i)\n",
    "        commu_Mat[count]=getSubGraphComm(sim, this_TimeStamp=i)\n",
    "        \n",
    "        components = [j for j in nx.connected_components(subGraph)] #all connected nodes in subgraph\n",
    "\n",
    "        max_ind = np.argmax([len(j) for j in nx.connected_components(subGraph)])\n",
    "        currGraph = nx.subgraph(currGraph, components[max_ind])\n",
    "        new_currGraph[count] = currGraph\n",
    "        currMat[count] = np.array(nx.adjacency_matrix(new_currGraph[count]).todense())\n",
    "\n",
    "#         commu = nx.communicability(new_currGraph[count])\n",
    "#         commu_Edges[count]=commu\n",
    "#         subSize = len(currGraph)\n",
    "        nodesList=list(currGraph.nodes)\n",
    "        nodesListFull[count]=nodesList\n",
    "\n",
    "#         commu_Mat[count] = np.array([commu[k][j] for k in nodesList for j in nodesList]).reshape(subSize,subSize)\n",
    "        count = count+1\n",
    "        \n",
    "    return nodesListFull,commu_Mat, currMat, new_currGraph, time_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASN Networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498c0f9a6ae749d9af8152f78c8e657f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "onAmp=[[] for i in range(len(ASN300))]\n",
    "shortestPath=[[None]*10 for i in range(len(ASN300))]\n",
    "for i in tqdm(range(len(ASN300))):\n",
    "    for j in range(len(ASN300[i])):\n",
    "        temp=getFarthestPairing(ASN300[i][j]['adj_matrix'])\n",
    "        shortestPath[i][j]=nx.shortest_path_length(ASN300[i][j]['G'],temp[0],temp[1])\n",
    "        onAmp[i].append(shortestPath[i][j]/5) #need to justify divide by 5 or come up with some other way\n",
    "        ASN300[i][j]['sp_amp']=onAmp[i][j]\n",
    "        ASN300[i][j]['Graph Theory']['Shortest Path']=shortestPath[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nonlineartrans(ASN300,onAmp,i,j,nodesList,stimulus):\n",
    "    dt = 1e-2\n",
    "    f=0.5\n",
    "    Time=5\n",
    "    period=1/f\n",
    "   #Instantiate Variables    \n",
    "    print('Running Linear Transformation Simulations')\n",
    "    dt = 1e-2\n",
    "    f=0.5\n",
    "    Time=5\n",
    "\n",
    "    #Choose Electrode Pattern\n",
    "    stimulus[0][i].append((stimulus__(biasType='AC',onAmp=onAmp[i][j],TimeVector=np.arange(0,Time,dt),f=f)))\n",
    "    stimulus[1][i].append((stimulus__(biasType='Drain',TimeVector=np.arange(0,Time,dt)))) #we don't want this drain to be active during training\n",
    "\n",
    "    #Initialise Output Variables\n",
    "    period=[]\n",
    "    TimeVector=[]\n",
    "    voltage=[]\n",
    "    conductance=[]\n",
    "    switches=[]\n",
    "    #Run Simulations\n",
    "    print('Parameter ' + str(i+1), ', Network ' + str(j+1))\n",
    "    #Run Simulations\n",
    "#     results=[]\n",
    "    # Connectivity=connectivity__('700nw_14533junctions.mat')\n",
    "    stimulus2 = [item for item in stimulus] #go through each list in the list and find the ith item\n",
    "#     set_trace()\n",
    "    results_ASN[j]=runSim(connectivity__(wires_dict=ASN300[i][j]),stimulus=stimulus2, contactMode='farthest', T = Time, dt = 0.001, onAmp = onAmp[i][j], biasType='AC',f=f,junctionMode='tunneling')\n",
    "    #wires_dict=newNetworkTest[chosenNetwork])\n",
    "    results_ASN[j].frequency=f\n",
    "    results_ASN[j].dt=0.001\n",
    "    period=1/f  \n",
    "\n",
    "#         name= r'/import/silo2/aloe8475/Documents/CODE/Data/Functional Connectivity/simulations_LinearTransformation_' + str(i)\n",
    "#         print('Saving 10 Simulations for Parameter ' +str(i+1))\n",
    "#         compressed_pickle([results_ASN],name)\n",
    "\n",
    "    print('Regressing Parameter ' + str(i+1), ', Network ' + str(j+1))\n",
    "    TimeVector=results_ASN[j].TimeVector\n",
    "    voltage=results_ASN[j].wireVoltage\n",
    "    conductance=results_ASN[j].conductance\n",
    "    switches=results_ASN[j].junctionSwitch\n",
    "\n",
    "    target1= (onAmp[i][j] * (-np.sign(TimeVector % period - period/2)))\n",
    "#             target2[j] = (4*onAmp[i]/period * abs((TimeVector-period/4) % period - period/2) - onAmp[i])\n",
    "#             target3[j] = (onAmp[i]/period * (TimeVector % period))\n",
    "#             target4[j] = (onAmp[i]*np.sin(4*np.pi*(1/period)*TimeVector))\n",
    "\n",
    "    if len(ASN300[i][j]['G']) >= 250:\n",
    "        nodesList[i][j]=[50,100,150,200,250,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)\n",
    "    elif len(ASN300[i][j]['G']) >= 200 and len(ASN300[i][j]['G']) < 250:\n",
    "        nodesList[i][j]=[50,100,150,200,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)  \n",
    "    elif len(ASN300[i][j]['G']) >= 150 and len(ASN300[i][j]['G']) < 200:\n",
    "        nodesList[i][j]=[50,100,150,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)  \n",
    "    elif len(ASN300[i][j]['G']) >= 100 and len(ASN300[i][j]['G']) < 150:\n",
    "        nodesList[i][j]=[50,100,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)\n",
    "    \n",
    "    nwSqu =[None]*len(nodesList[i][j])\n",
    "    countK=0\n",
    "    for k in nodesList[i][j]: #loop through sets of nodes for regression\n",
    "        print('Running Regression: ' + str(k) + ' nodes')\n",
    "        ResultSqu=[]\n",
    "        ResultSqu = nonLinearTrans(results_ASN[j],'Square',k, repeats=50) #simulation, type of signal, number of nodes to sample from, number of linear regression repetitions (take avg)\n",
    "        nwSqu[countK]=ResultSqu['accuracy']\n",
    "        ASN300[i][j]['Accuracy']['Linear Transformation'][countK]=nwSqu[countK]\n",
    "        countK=countK+1\n",
    "            #Save networks so we don't have to run this every time\n",
    "            \n",
    "    accRandom=nwSqu\n",
    "    return accGrid,ASN300                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ASN300' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5c30343dde8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnodesList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASN300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstimulus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASN300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASN300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASN300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASN300\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ASN300' is not defined"
     ]
    }
   ],
   "source": [
    "nodesList=[[None]*10 for i in range(len(ASN300))]\n",
    "stimulus=[[[] for i in range(len(ASN300))],[[] for i in range(len(ASN300))]]\n",
    "init=[]\n",
    "for i in range(len(ASN300)):\n",
    "    for j in range(len(ASN300[i])):\n",
    "        init.append(nonlineartrans,ASN300,onAmp,i,j,nodesList,stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=para_run(nonlineartrans,init,nCPU=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate nodesList\n",
    "nodesList=[[None]*10 for i in range(len(ASN300))]\n",
    "for i in range(len(ASN300)):\n",
    "    for j in range(len(ASN300[i])): #for each network:\n",
    "        if len(ASN300[i][j]['G']) >= 250:\n",
    "            nodesList[i][j]=[50,100,150,200,250,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)\n",
    "        elif len(ASN300[i][j]['G']) >= 200 and len(ASN300[i][j]['G']) < 250:\n",
    "            nodesList[i][j]=[50,100,150,200,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)  \n",
    "        elif len(ASN300[i][j]['G']) >= 150 and len(ASN300[i][j]['G']) < 200:\n",
    "            nodesList[i][j]=[50,100,150,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)  \n",
    "        elif len(ASN300[i][j]['G']) >= 100 and len(ASN300[i][j]['G']) < 150:\n",
    "            nodesList[i][j]=[50,100,len(ASN300[i][j]['G'])]#range(50, len(ws300[i][0])+1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DO NOT DELETE COMMENTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Current and Communicability Matrices:\n",
    "# if ( os.path.isfile(r'/import/silo2/aloe8475/Documents/CODE/Data/Functional Connectivity/simulations_LinearTransformation_29')):\n",
    "#     print('Running Communicability Analysis')\n",
    "#     time_index=[[None]*10 for i in range(len(ASN300))]\n",
    "#     junctions=[[None]*10 for i in range(len(ASN300))]\n",
    "#     sources=[[None]*10 for i in range(len(ASN300))]\n",
    "#     drains=[[None]*10 for i in range(len(ASN300))]\n",
    "#     count1=0\n",
    "#     count2=0\n",
    "#     count3=0\n",
    "#     for i in tqdm(range(len(ASN300))):\n",
    "#         check_memory()\n",
    "#         #load corresponding results_ASN file\n",
    "#         print('Loading Parameter ' + str(i+1) +' - All Networks')\n",
    "#         [results_ASN]=decompress_pickle(r'/import/silo2/aloe8475/Documents/CODE/Data/Functional Connectivity/simulations_LinearTransformation_'+str(i))\n",
    "#         print('Loaded Parameter ' + str(i+1) +' - All Networks')\n",
    "#         check_memory()\n",
    "#         for j in range(len(results_ASN)):\n",
    "#             print('Calculating COMM Matrix for Parameter ' + str(i+1) +', Network ' + str(j+1))\n",
    "#             nodesListASN_LT,commuMatASN_LT,currMatASN_LT,currGraphASN_LT,time_index[i][j]=commCurr(results_ASN[j]) #calculate communicability every 500 time steps for each network\n",
    "#             junctions[i][j]=results_ASN[j].junctionSwitch #save junction switch\n",
    "#             sources[i][j]=results_ASN[j].sources[0]\n",
    "#             drains[i][j]=results_ASN[j].drains[0]\n",
    "#               ASN300[i][j]['Graph Theory']['COMM Mat']=commuMatASN_LT\n",
    "#               ASN300[i][j]['Graph Theory']['Nodes List']=nodesListASN_LT\n",
    "#               ASN300[i][j][j]['Graph Theory']['Current Matrix']=currMatASN_LT\n",
    "#               ASN300[i][j][j]['Graph Theory']['Subgraph']=currGraphASN_LT\n",
    "\n",
    "\n",
    "#             if i < len(cluster1):\n",
    "#                 cluster1[count1][j]['Graph Theory']['COMM Mat']=commuMatASN_LT\n",
    "#                 cluster1[count1][j]['Graph Theory']['Nodes List']=nodesListASN_LT\n",
    "#                 cluster1[count1][j]['Graph Theory']['Current Matrix']=currMatASN_LT\n",
    "#                 cluster1[count1][j]['Graph Theory']['Subgraph']=currGraphASN_LT\n",
    "#                 if j == len(results_ASN)-1:\n",
    "#                     count1=count1+1\n",
    "#             elif i >= len(cluster1) and i < (len(cluster1) + len(cluster2)):\n",
    "#                 cluster2[count2][j]['Graph Theory']['COMM Mat']=commuMatASN_LT\n",
    "#                 cluster2[count2][j]['Graph Theory']['Nodes List']=nodesListASN_LT\n",
    "#                 cluster2[count2][j]['Graph Theory']['Current Matrix']=currMatASN_LT\n",
    "#                 cluster2[count2][j]['Graph Theory']['Subgraph']=currGraphASN_LT\n",
    "#                 if j == len(results_ASN)-1: \n",
    "#                     count2=count2+1\n",
    "#             else:\n",
    "#                 cluster3[count3][j]['Graph Theory']['COMM Mat']=commuMatASN_LT\n",
    "#                 cluster3[count3][j]['Graph Theory']['Nodes List']=nodesListASN_LT\n",
    "#                 cluster3[count3][j]['Graph Theory']['Current Matrix']=currMatASN_LT\n",
    "#                 cluster3[count3][j]['Graph Theory']['Subgraph']=currGraphASN_LT\n",
    "#                 if j == len(results_ASN)-1:                \n",
    "#                     count3=count3+1\n",
    "#         del results_ASN, commuMatASN_LT, nodesListASN_LT, currMatASN_LT, currGraphASN_LT\n",
    "        \n",
    "# else:\n",
    "#     print('Communicability Analysis Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save Communicability Matrices so we don't have to load it all again:\n",
    "# #Update pickle file:\n",
    "# # if ( os.path.isfile(r'C:/Users/61424/Documents/GitHub/CODE/Analysis/Functional Connectivity/Functional Tasks/networks_LinearTransformation.pkl')):\n",
    "# name='networks_LinearTransformation.pkl'\n",
    "# with open(name, 'wb') as f:\n",
    "#     pickle.dump([ASN300,cluster1,cluster2,cluster3,time_index,nodesList], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #network junctions switches:\n",
    "# fig1=plt.figure(figsize=(15,15))\n",
    "# ax=[None]*numNetworks\n",
    "# axBig = fig1.add_subplot(111)\n",
    "# axBig.set_frame_on(False)\n",
    "# axBig.set_yticklabels([])\n",
    "# axBig.set_xticklabels([])\n",
    "# plt.xlabel('Time',fontsize=30,labelpad=15)\n",
    "# plt.ylabel('Num On Switches',fontsize=30,labelpad=15)\n",
    "# count1=0\n",
    "# count2=0\n",
    "# count3=0\n",
    "\n",
    "# for i in range(numNetworks):\n",
    "#     ax[i]=fig1.add_subplot(numNetworks/4, numNetworks/6, i+1)\n",
    "#     fig1.subplots_adjust(hspace=.4)\n",
    "#     if i < len(cluster1):\n",
    "#         ax[i].set_title('Cluster 1 Network ' + str(count1+1),fontsize=15)\n",
    "#         count1=count1+1\n",
    "#     elif i >= len(cluster1) and i < (len(cluster1) + len(cluster2)):\n",
    "#         ax[i].set_title('Cluster 2 Network ' + str(count2+1),fontsize=15)\n",
    "#         count2=count2+1\n",
    "#     else:\n",
    "#         ax[i].set_title('Cluster 3 Network ' + str(count3+1),fontsize=15)\n",
    "#         count3=count3+1\n",
    "#     plt.plot(np.sum(junctions[i][j],1))\n",
    "#     #votlage as title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=3000\n",
    "\n",
    "# sim=results_ASN[0]\n",
    "# subGraph=getOnGraph(sim,i)\n",
    "# components = [j for j in nx.connected_components(subGraph)] #all connected nodes in subgraph\n",
    "\n",
    "# currMat = np.zeros((sim.numOfWires,sim.numOfWires))\n",
    "# edgeList = sim.connectivity.edge_list\n",
    "# currMat[edgeList[:,0], edgeList[:,1]] = sim.junctionVoltage[i,:]/sim.junctionResistance[i,:] #-1,:\n",
    "# currMat = currMat + currMat.T\n",
    "# currGraph = nx.from_numpy_array(currMat)\n",
    "# subGraph = getOnGraph(sim, this_TimeStamp=i)\n",
    "\n",
    "# components = [j for j in nx.connected_components(subGraph)] #all connected nodes in subgraph\n",
    "\n",
    "# max_ind = np.argmax([len(j) for j in nx.connected_components(subGraph)])\n",
    "# currGraph = nx.subgraph(currGraph, components[max_ind])\n",
    "\n",
    "# commu = nx.communicability(currGraph)\n",
    "# commu_Edges=commu\n",
    "# subSize = len(currGraph)\n",
    "# nodesList=list(currGraph.nodes)\n",
    "# commu_Mat = np.array([commu[k][j] for k in nodesList for j in nodesList]).reshape(subSize,subSize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Elegans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On Amp as a function of shortestPath\n",
    "onAmp=[]\n",
    "shortestPathElegans=[]\n",
    "temp=getFarthestPairing(Elegans['adj_matrix'])\n",
    "shortestPathElegans=nx.shortest_path_length(Elegans['G'],temp[0],temp[1])\n",
    "onAmpElegans=shortestPathElegans/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network C.Elegans\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c74583ed3a4446bbd1d39bec540cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Running Simulation ', max=5000, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 14:08:47,776:INFO:First current path [9, 38, 16, 169, 105, 98, 36] formed at time = 0.773 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Regression: 50 nodes\n",
      "Running Regression: 100 nodes\n",
      "Running Regression: 150 nodes\n",
      "Running Regression: 200 nodes\n",
      "Running Regression: 250 nodes\n",
      "Running Regression: 277 nodes\n"
     ]
    }
   ],
   "source": [
    "#Instantiate Variables       \n",
    "stimulus_E=[[],[]]\n",
    "accSqu=[]\n",
    "#    accTri=[]\n",
    "#    accSaw=[]\n",
    "#    accDbl=[]\n",
    "maxSqu=[]\n",
    "#    maxTri=[]\n",
    "#    maxSaw=[]\n",
    "#    maxDbl=[]\n",
    "dt = 1e-2\n",
    "f=0.5\n",
    "Time=5\n",
    "# onAmp=2#[1.5,2,4,4,4,6,6,6,6,6,6,6,4,4,4,4,6,4,4,4,4,3,2,1.5]\n",
    "\n",
    "#Choose Electrode Pattern\n",
    "\n",
    "stimulus_E[0].append((stimulus__(biasType='AC',onAmp=onAmpElegans,TimeVector=np.arange(0,Time,dt),f=f)))\n",
    "stimulus_E[1].append((stimulus__(biasType='Drain',TimeVector=np.arange(0,Time,dt)))) #we don't want this drain to be active during training\n",
    "\n",
    "#Initialise Output Variables\n",
    "period=[]\n",
    "TimeVector=[]\n",
    "voltage=[]\n",
    "conductance=[]\n",
    "switches=[]\n",
    "results=[None]*len([elegansGraph])\n",
    "# Voltage=[None]*len(ASN300)\n",
    "# Switches=[None]*len(ASN300)\n",
    "\n",
    "\n",
    "nwSqu = []*len([elegansGraph])\n",
    "\n",
    "#Run Simulations\n",
    "# for i in range(len(ASN300)): #for each network\n",
    "print('Network C.Elegans')\n",
    "#Run Simulations\n",
    "#     results=[]\n",
    "# Connectivity=connectivity__('700nw_14533junctions.mat')\n",
    "stimulus2 = [item for item in stimulus_E] #go through each list in the list and find the ith item\n",
    "#     set_trace()\n",
    "results=runSim(connectivity__(graph=elegansGraph),stimulus=stimulus2, contactMode='farthest', T = Time, dt = 0.001, onAmp = onAmpElegans, biasType='AC',f=f,junctionMode='tunneling')\n",
    "#wires_dict=newNetworkTest[chosenNetwork])\n",
    "results.frequency=f\n",
    "results.dt=0.001\n",
    "period=1/f\n",
    "\n",
    "TimeVector=results.TimeVector\n",
    "voltage=results.wireVoltage\n",
    "conductance=results.conductance\n",
    "switches=results.junctionSwitch\n",
    "\n",
    "stepNodes=len(elegansGraph)-1 #first use all nodes\n",
    "sizes2=len(elegansGraph)\n",
    "nwOutputs = [None]* int(sizes2/stepNodes)\n",
    "\n",
    "outputNodes2=[]\n",
    "\n",
    "for k in range(stepNodes,sizes2+1,stepNodes): #stepping up nodes\n",
    "    np.random.seed(69)\n",
    "\n",
    "    outputNodes2.append(voltage[:,np.random.choice(len(voltage[0,:]),size=k,replace=False)]) #take all the times (:) for a random j nodes\n",
    "\n",
    "    nwOutputs=outputNodes2 #Length of nwOutputs is k (list)\n",
    "\n",
    "target1=[None]*len(nwOutputs)\n",
    "#     target2=[None]*len(nwOutputs)\n",
    "#     target3=[None]*len(nwOutputs)\n",
    "#     target4=[None]*len(nwOutputs)\n",
    "#     target5=[None]*len(nwOutputs)\n",
    "\n",
    "for j in range(len(nwOutputs)):\n",
    "    target1[j] = (onAmpElegans * (-np.sign(TimeVector % period - period/2)))\n",
    "#         target2[j] = (4*onAmp[i]/period * abs((TimeVector-period/4) % period - period/2) - onAmp[i])\n",
    "#         target3[j] = (onAmp[i]/period * (TimeVector % period))\n",
    "#         target4[j] = (onAmp[i]*np.sin(4*np.pi*(1/period)*TimeVector))\n",
    "\n",
    "\n",
    "#        nwTri     = np.zeros(len(nwOutputs))\n",
    "#        nwSaw     = np.zeros(len(nwOutputs))\n",
    "#        nwDbl     = np.zeros(len(nwOutputs))\n",
    "#     nwMG      = [[None]*networksLoad,[None]*len(nwOutputs[0])]\n",
    "\n",
    "ResultSqu=[]\n",
    "#        ResultTri=[]\n",
    "#        ResultSaw=[]\n",
    "accuracy=[]\n",
    "#        accuracyTri=[]\n",
    "#        accuracySaw=[]\n",
    "#        accuracyDbl=[]\n",
    "output=[]\n",
    "mSqu=[]\n",
    "#        mTri=[]\n",
    "#        mSaw=[]\n",
    "#        mDbl=[]\n",
    "\n",
    "# RUN LINEAR TRANSFORMATION\n",
    "nodesListElegans=[50,100,150,200,250,len(Elegans['G'])]\n",
    "for j in nodesListElegans: #range(50, len(Elegans['G'])+1,50): #loop through sets of nodes \n",
    "    print('Running Regression: ' + str(j) + ' nodes')\n",
    "    \n",
    "    ResultSqu=nonLinearTrans(results,'Square',j, repeats=50) #NOKEVregression(target1[j],nwOutputs[j].T)[0]\n",
    "    \n",
    "    nwSqu.append(ResultSqu['accuracy'])#(1 - rnMSE)\n",
    "    \n",
    "    \n",
    "#THRESHOLD FOR COMMUNICABILITY MEASURE\n",
    "results=[results]\n",
    "# # From Matlab:\n",
    "# resistance=results.junctionResistance\n",
    "# for i in range(len(resistance)):\n",
    "#     if resistance[i]<10000:\n",
    "#         resistance[i][resistance[i]<10000]=1\n",
    "# else:\n",
    "#     resistance[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Elegans Networks\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.isfile('elegans_LinearTransformation.pkl')): #if we haven't saved the file\n",
    "    #Current and Communicability Matrices\n",
    "    commuMatElegans_LT=[None]*len(results)\n",
    "    currMatElegans_LT=[None]*len(results)\n",
    "    # for i in tqdm(range(len(results))):\n",
    "    nodesListElegans_LT,commuMatElegans_LT,currMatElegans_LT,new_currGraphElegans_LT,time_indexElegans=commCurr(results[0])\n",
    "\n",
    "    Elegans['Graph Theory']['COMM Mat']=commuMatElegans_LT\n",
    "    Elegans['Graph Theory']['Nodes List']=nodesListElegans_LT\n",
    "    Elegans['Graph Theory']['Current Matrix']=currMatElegans_LT\n",
    "    Elegans['Graph Theory']['Subgraph']=new_currGraphElegans_LT\n",
    "    Elegans['Accuracy']['Linear Transformation']=nwSqu\n",
    "    \n",
    "    #Save networks so we don't have to run this every time\n",
    "    print('Saving Elegans Networks')\n",
    "    name='elegans_LinearTransformation.pkl'\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump([Elegans], f)\n",
    "else:\n",
    "    name='elegans_LinearTransformation.pkl'\n",
    "    print('Loading Elegans Networks')\n",
    "    file = open(name, 'rb')\n",
    "#     [ASN300,cluster1,cluster2,cluster3,time_index,nodesList] = pickle.load(file)\n",
    "#     [ASN300,cluster1,cluster2,cluster3] = pickle.load(file)\n",
    "    [Elegans] = pickle.load(file)\n",
    "\n",
    "    print('Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMUNICABILITY 12/05 - Need to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Assign weights to edges based on COMMUNICABILITY:\n",
    "\n",
    "#Cluster 1:\n",
    "G_C1=[]\n",
    "weights_C1=[]\n",
    "for i in range(len(cluster1)): #for each network\n",
    "    G_C1.append([None]*len(cluster1[i]['Graph Theory']['COMM Mat']))\n",
    "    weights_C1.append([None]*len(cluster1[i]['Graph Theory']['COMM Mat']))\n",
    "    for j in range(len(cluster1[i]['Graph Theory']['COMM Mat'])): #for each timestamp \n",
    "        G_C1[i][j]=cluster1[i]['Graph Theory']['Subgraph'][j]\n",
    "        weights_C1[i][j]=cluster1[i]['Graph Theory']['COMM Mat'][j]\n",
    "        for e in G_C1[i][j].edges(): #for each edge pairing\n",
    "            G_C1[i][j][e[0]][e[1]]['weight'] = weights_C1[i][j][e]\n",
    "            \n",
    "#Cluster 2:\n",
    "G_C2=[]\n",
    "weights_C2=[]\n",
    "for i in range(len(cluster2)): #for each network\n",
    "    G_C2.append([None]*len(cluster2[i]['Graph Theory']['COMM Mat']))\n",
    "    weights_C2.append([None]*len(cluster2[i]['Graph Theory']['COMM Mat']))\n",
    "    for j in range(len(cluster2[i]['Graph Theory']['COMM Mat'])): #for each timestamp \n",
    "        G_C2[i][j]=cluster2[i]['Graph Theory']['Subgraph'][j]\n",
    "        weights_C2[i][j]=cluster2[i]['Graph Theory']['COMM Mat'][j]\n",
    "        for e in G_C2[i][j].edges(): #for each edge pairing\n",
    "            G_C2[i][j][e[0]][e[1]]['weight'] = weights_C2[i][j][e]\n",
    "            \n",
    "#Cluster 3:\n",
    "G_C3=[]\n",
    "weights_C3=[]\n",
    "for i in range(len(cluster3)): #for each network\n",
    "    G_C3.append([None]*len(cluster3[i]['Graph Theory']['COMM Mat']))\n",
    "    weights_C3.append([None]*len(cluster3[i]['Graph Theory']['COMM Mat']))\n",
    "    for j in range(len(cluster3[i]['Graph Theory']['COMM Mat'])): #for each timestamp \n",
    "        G_C3[i][j]=cluster3[i]['Graph Theory']['Subgraph'][j]\n",
    "        weights_C3[i][j]=cluster3[i]['Graph Theory']['COMM Mat'][j]\n",
    "        for e in G_C3[i][j].edges(): #for each edge pairing\n",
    "            G_C3[i][j][e[0]][e[1]]['weight'] = weights_C3[i][j][e]\n",
    "            \n",
    "#C Elegans:\n",
    "G_E=[]\n",
    "weights_E=[]\n",
    "temp=[None]\n",
    "for i in range(len(temp)): #for each network\n",
    "    temp[i]=Elegans\n",
    "    G_E.append([None]*len(temp[i]['Graph Theory']['COMM Mat']))\n",
    "    weights_E.append([None]*len(temp[i]['Graph Theory']['COMM Mat']))\n",
    "    for j in range(len(temp[i]['Graph Theory']['COMM Mat'])): #for each timestamp \n",
    "        G_E[i][j]=temp[i]['Graph Theory']['Subgraph'][j]\n",
    "        weights_E[i][j]=temp[i]['Graph Theory']['COMM Mat'][j]\n",
    "        for e in G_E[i][j].edges(): #for each edge pairing\n",
    "            G_E[i][j][e[0]][e[1]]['weight'] = weights_E[i][j][e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot timeseries:\n",
    "fig=plt.figure()\n",
    "plt.plot(stimulus[0][0].signal)#Stimulus[electrode type][network number]\n",
    "plt.xticks(range(50,151,50),labels=range(500,1501,500))\n",
    "plt.axvline(50,linestyle='--',color='k')\n",
    "plt.axvline(150,linestyle='--',color='k')\n",
    "\n",
    "# PLOT SUBGRAPH ONLY:\n",
    "fig1=plt.figure(figsize=(15,20))\n",
    "# for i in range(len(cluster1)):\n",
    "ax=[None]*(len(cluster1[0]['Graph Theory']['COMM Mat']))\n",
    "\n",
    "#Find Maximum COMM\n",
    "vmax1=[]\n",
    "for i in range(len(G[0])):\n",
    "    if bool(nx.get_edge_attributes(G[0][i],'weight')):\n",
    "        edges,weights2 = zip(*nx.get_edge_attributes(G[0][i],'weight').items())\n",
    "        vmax1.append(max(weights2))\n",
    "    else:\n",
    "        weights2=[]\n",
    "        edges=[]\n",
    "    \n",
    "count1=0\n",
    "times=range(time_index[0][0],time_index[0][1],time_index[0][2])\n",
    "for j in range(len(cluster1[0]['Graph Theory']['COMM Mat'])): #for each timestamp\n",
    "    ax[j]=fig1.add_subplot(7,3, j+1)\n",
    "    ax[j].set_title('Cluster 1, NW 1, Timestamp ' + str(times[j]),fontsize=15)\n",
    "    if bool(nx.get_edge_attributes(G[0][j],'weight')):\n",
    "        edges,weights2 = zip(*nx.get_edge_attributes(G[0][j],'weight').items())\n",
    "    else:\n",
    "        weights2=[]\n",
    "        edges=[]\n",
    "        \n",
    "    posSub=nx.drawing.layout.kamada_kawai_layout(G[0][j])\n",
    "    # fig=plt.figure(figsize=(30,30))\n",
    "    cmap=plt.cm.autumn_r\n",
    "    vmin = 1\n",
    "    vmax=max(vmax1)\n",
    "    \n",
    "    #NORMALIZE WEIGHTS:\n",
    "    normalize=plt.Normalize(vmin = vmin, vmax=vmax)\n",
    "    colors=[cmap(normalize(value)) for value in weights2]\n",
    "    \n",
    "    nx.draw(G[0][j],posSub,node_color='k',edgelist=edges,edge_color=colors, width=2,edge_cmap=cmap)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = vmin, vmax=vmax))\n",
    "    sm._A = []\n",
    "\n",
    "    plt.colorbar(sm)\n",
    "    \n",
    "    count1=count1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot timeseries:\n",
    "# fig=plt.figure()\n",
    "# plt.plot(stimulus[0][0].signal)#Stimulus[electrode type][network number]\n",
    "# plt.xticks(range(50,151,50),labels=range(500,1501,500))\n",
    "# plt.axvline(50,linestyle='--',color='k')\n",
    "# plt.axvline(150,linestyle='--',color='k')\n",
    "# # plt.xticks(range(0,501,50),labels=range(0,5001,500))\n",
    "\n",
    "G=[]\n",
    "clusterNum=3#'E' #CHANGE CLUSTER TO PLOT HERE, for elegans = 'E'\n",
    "if clusterNum==1:\n",
    "    G=G_C1\n",
    "    cluster=cluster1\n",
    "    accuracy=[[None]*len(cluster1accuracy) for i in range(len(cluster1accuracy[0]))]\n",
    "    for i in range(len(cluster1accuracy)):\n",
    "        for j in range(len(cluster1accuracy[i])):\n",
    "            accuracy[j][i]=cluster1accuracy[i][j]\n",
    "    count=0\n",
    "elif clusterNum==2:\n",
    "    G=G_C2\n",
    "    cluster=cluster2\n",
    "    accuracy=[[None]*len(cluster2accuracy) for i in range(len(cluster2accuracy[0]))]\n",
    "    for i in range(len(cluster2accuracy)):\n",
    "        for j in range(len(cluster2accuracy[i])):\n",
    "            accuracy[j][i]=cluster2accuracy[i][j]\n",
    "    count=len(cluster1)\n",
    "elif clusterNum==3:\n",
    "    G=G_C3\n",
    "    cluster=cluster3\n",
    "    accuracy=[[None]*len(cluster3accuracy) for i in range(len(cluster3accuracy[0]))]\n",
    "    for i in range(len(cluster3accuracy)):\n",
    "        for j in range(len(cluster3accuracy[i])):\n",
    "            accuracy[j][i]=cluster3accuracy[i][j]\n",
    "    count=len(cluster1)+len(cluster2)\n",
    "elif clusterNum=='E':\n",
    "    G=G_E\n",
    "    cluster=[None]\n",
    "    cluster[0]=Elegans\n",
    "    accuracy=Elegans['Accuracy']['Linear Transformation']\n",
    "\n",
    "    #Plot Figures\n",
    "fig=[None]*len(G)\n",
    "for i in tqdm(range(len(G))): #For Each Network\n",
    "    #initialise variables:\n",
    "    pos=[]\n",
    "    sm=[]\n",
    "    ax=[None]*(len(cluster[i]['Graph Theory']['COMM Mat']))\n",
    "    \n",
    "    #Find Maximum COMM\n",
    "    vmax1=[]\n",
    "    for j in range(len(G[i])):\n",
    "        if bool(nx.get_edge_attributes(G[i][j],'weight')):\n",
    "            edges,weights2 = zip(*nx.get_edge_attributes(G[i][j],'weight').items())\n",
    "            vmax1.append(max(weights2))\n",
    "        else:\n",
    "            weights2=[]\n",
    "            edges=[]\n",
    "\n",
    "    #PLOT NETWORK + COMMUNICABILITY OVERLAYED\n",
    "    fig[i]=plt.figure(figsize=(40,30))\n",
    "    pos=nx.drawing.layout.kamada_kawai_layout(cluster[i]['G'])\n",
    "    for j in range(len(cluster[i]['Graph Theory']['COMM Mat'])): #for each timestamp\n",
    "        colors=[]\n",
    "        ax[j]=fig[i].add_subplot(4,5, j+1) #CHANGE THIS FOR MORE/LESS TIMESTAMPS (rows, columns, subplot number)\n",
    "        ax[j].set_title('Cluster ' + str(clusterNum)+ ', NW ' + str(i+1) + ' Timestamp ' + str(times[j]),fontsize=20)\n",
    "        nx.draw_networkx(cluster[i]['G'],pos,edge_color='gray',alpha=0.1,with_labels=False,node_size=30)\n",
    "        colors=range(20)\n",
    "        cmap=plt.cm.autumn_r\n",
    "        vmin = 1\n",
    "        vmax=max(vmax1)\n",
    "\n",
    "        #NORMALIZE WEIGHTS:\n",
    "        normalize=plt.Normalize(vmin = vmin, vmax=vmax)\n",
    "        colors=[cmap(normalize(value)) for value in weights2]\n",
    "        if clusterNum=='E':\n",
    "            nx.draw_networkx(cluster[i]['G'],pos,nodelist=[results[i].sources[0]],node_color='g',edgelist=[],with_labels=False)\n",
    "            nx.draw_networkx(cluster[i]['G'],pos,nodelist=[results[i].drains[0]],node_color='r',edgelist=[],with_labels=False)\n",
    "        else:\n",
    "            nx.draw_networkx(cluster[i]['G'],pos,nodelist=[sources[count+i]],node_color='g',edgelist=[],with_labels=False)\n",
    "            nx.draw_networkx(cluster[i]['G'],pos,nodelist=[drains[count+i]],node_color='r',edgelist=[],with_labels=False)\n",
    "        nx.draw_networkx_edges(cluster[i]['G'],pos,edgelist=G[i][j].edges,edge_color=colors,alpha=0.8, width=3,edge_cmap=cmap)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = vmin, vmax=vmax))\n",
    "        sm._A = []\n",
    "\n",
    "        cb=plt.colorbar(sm)\n",
    "        cb.set_label(label='Communicability', size='large', weight='bold')\n",
    "        \n",
    "        if j == 0:\n",
    "            if clusterNum == 'E':\n",
    "                plt.text(0.05,0.9,'Max LT Acc:'+\"{0:.2f}\".format(np.max(accuracy)),transform=ax[j].transAxes,fontsize=15) #this plots Smallworldness as text in a relative position on each subplot\n",
    "            else:\n",
    "                plt.text(0.05,0.9,'Max LT Acc:'+\"{0:.2f}\".format(np.nanmax(np.array(accuracy[i],dtype=float))),transform=ax[j].transAxes,fontsize=15) #this plots Smallworldness as text in a relative position on each subplot\n",
    "    if clusterNum=='E':\n",
    "        plt.savefig(r'C:\\Users\\61424\\Documents\\GitHub\\CODE\\Data\\Figures\\Functional Connectivity\\Communicability\\Communicability Conductance Subgraph Elegans.jpg')\n",
    "    else:\n",
    "        plt.savefig(r'C:\\Users\\61424\\Documents\\GitHub\\CODE\\Data\\Figures\\Functional Connectivity\\Communicability\\Communicability Conductance Subgraph Cluster '+ str(clusterNum) +' NW ' + str(i+1) + '.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
